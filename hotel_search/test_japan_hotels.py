#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ—¥æœ¬é…’åº—æœç´¢ç³»ç»Ÿæµ‹è¯•ä»£ç 
ä»JSONæ–‡ä»¶åŠ è½½æµ‹è¯•æ•°æ®ï¼Œæ‰§è¡Œå„ç§æµ‹è¯•ç”¨ä¾‹
"""

import json
import time
from typing import List, Dict, Set
from dataclasses import dataclass
from collections import defaultdict
import os

@dataclass
class JapanHotelInfo:
    """æ—¥æœ¬é…’åº—ä¿¡æ¯"""
    hotel_id: str
    hotel_name_cn: str
    hotel_name_en: str
    hotel_name_jp: str
    city_name_cn: str
    city_name_en: str
    city_name_jp: str
    region_name: str
    address: str
    country: str
    search_count: int
    latitude: float = None
    longitude: float = None
    price_range: str = ""
    star_rating: int = 0

@dataclass
class JapanHotelSuggestElem:
    """æ—¥æœ¬é…’åº—å»ºè®®å…ƒç´ """
    display_name: str
    hotel_name: str
    city_name: str
    region_name: str
    country: str
    hotel_id: str
    price_range: str = ""
    star_rating: int = 0

class JapanHotelQueryNormalizer:
    """æ—¥æœ¬é…’åº—æŸ¥è¯¢å½’ä¸€åŒ–å™¨"""
    
    STOP_WORDS = {
        "é…’åº—", "hotel", "æ—…é¦†", "inn", "å®¾é¦†", "guesthouse", "åº¦å‡æ‘", "resort",
        "é¥­åº—", "restaurant", "ä½å®¿", "accommodation", "å…¬å¯“", "apartment",
        "æ°‘å®¿", "hostel", "é’å¹´æ—…ç¤¾", "youth hostel", "å•†åŠ¡é…’åº—", "business hotel",
        "ãƒ›ãƒ†ãƒ«", "æ—…é¤¨", "å®¿", "æ°‘å®¿", "ãƒ“ã‚¸ãƒã‚¹ãƒ›ãƒ†ãƒ«"
    }
    
    # æ—¥æœ¬åŸå¸‚æ‹¼éŸ³æ˜ å°„
    JAPAN_PINYIN_MAP = {
        # ä¸œäº¬éƒ½
        "ä¸œäº¬": "dj", "æ–°å®¿": "xs", "æ¶©è°·": "sg", "æ± è¢‹": "cd", "ç§‹å¶åŸ": "qyy", 
        "æµ…è‰": "qc", "ä¸Šé‡": "sy", "é“¶åº§": "yz", "ç­‘åœ°": "zd", "å“å·": "pc", 
        "æ—¥æœ¬æ¡¥": "rbq", "æ—¥æš®é‡Œ": "rml", "å…­æœ¬æœ¨": "lbm", "åŸå®¿": "ys", "è¡¨å‚é“": "bcd",
        "é’å±±": "qs", "ä»£å®˜å±±": "dgs", "æƒ æ¯”å¯¿": "hbs", "ä¸­ç›®é»‘": "zmm", "ç›®é»‘": "mm",
        "äº”åç”°": "wft", "å¤§å´": "ds", "ç”°ç”º": "tm", "æ»¨æ¾ç”º": "bsm", "ä¸œäº¬ç«™": "djz",
        "æœ‰ä¹ç”º": "ylt", "æ–°æ¡¥": "xq", "æ±ç•™": "xl", "å°åœº": "tc", "ä¸°æ´²": "fz",
        
        # å¤§é˜ªåºœ
        "å¤§é˜ª": "os", "æ¢…ç”°": "md", "éš¾æ³¢": "nb", "å¿ƒæ–‹æ¡¥": "xzb", "é“é¡¿å €": "ddk",
        "å¤©ç‹å¯º": "twz", "æ–°å¤§é˜ª": "xos", "æ·€å±‹æ¡¥": "dyq", "æœ¬ç”º": "bm", "è¥¿æ¢…ç”°": "xmd",
        "ä¸œæ¢…ç”°": "dmd", "åŒ—æ–°åœ°": "bxd", "å—æ£®ç”º": "nsm", "å¤©æ»¡æ¡¥": "tmq", "äº¬æ¡¥": "jq",
        "è°·ç”º": "gt", "æ£®ä¹‹å®«": "szg", "ç‰é€ ": "yz", "é¹¤æ¡¥": "hq", "ä»Šé‡Œ": "jl",
        
        # äº¬éƒ½åºœ
        "äº¬éƒ½": "jd", "å››æ¡": "st", "ä¸‰æ¡": "st", "äºŒæ¡": "et", "ä¹Œä¸¸": "wm",
        "æ²³åŸç”º": "hym", "ç¥—å›­": "zy", "æ¸…æ°´å¯º": "qss", "é‡‘é˜å¯º": "jgs", "é“¶é˜å¯º": "ygs",
        "å²šå±±": "ls", "ä¼è§": "fj", "ç¨»è·": "dn", "ä¸œç¦å¯º": "dfs", "å—ç¦…å¯º": "nzs",
        "è¥¿é˜µ": "xz", "ä¸Šäº¬": "sj", "ä¸­äº¬": "zj", "ä¸‹äº¬": "xj", "å·¦äº¬": "zj",
        
        # æ¨ªæ»¨å¸‚
        "æ¨ªæ»¨": "hb", "å…³å†…": "gn", "æ¨±æœ¨ç”º": "ymm", "çŸ³å·ç”º": "scm", "å±±æ‰‹": "ss",
        "å…ƒç”º": "ym", "ä¸­åè¡—": "zhj", "æ¸¯æœªæ¥": "gwl", "æ¨ªæ»¨ç«™": "hbz", "æ–°æ¨ªæ»¨": "xhb",
        "ä¿åœŸè°·": "bty", "ä¸œç¥å¥ˆå·": "dsnj", "æ¨ªæ»¨æ¡¥": "hbq", "å¹³æ²¼æ¡¥": "pnq", "è¥¿æ¨ªæ»¨": "xhb",
        
        # åå¤å±‹å¸‚
        "åå¤å±‹": "mgy", "è£": "r", "å¤§é¡»": "ds", "åå¤å±‹ç«™": "mgyz", "é‡‘å±±": "js",
        "ä¸œåˆ«é™¢": "dby", "ä¸Šå‰æ´¥": "sqt", "çŸ¢åœºç”º": "ycm", "ä¹…å±‹å¤§é€š": "jydt", "ä¼è§": "fj",
        "ä¸¸ä¹‹å†…": "wzn", "é”¦": "j", "å¤§æ´¥é€š": "dzt", "æ–°è£": "xr", "ä»Šæ± ": "jc",
        
        # ç¥æˆ·å¸‚
        "ç¥æˆ·": "sb", "ä¸‰å®«": "sg", "å…ƒç”º": "ym", "ç¥æˆ·ç«™": "sbz", "æ–°ç¥æˆ·": "xsb",
        "å…­ç”²": "lj", "æ»©": "t", "ä¸œæ»©": "dt", "è¥¿å®«": "xg", "èŠ¦å±‹": "ly",
        "æ˜çŸ³": "ms", "å§¬è·¯": "jl", "åŠ å¤å·": "jkg", "é«˜ç ‚": "ts", "è¥¿æ˜çŸ³": "xms",
        
        # ç¦å†ˆå¸‚
        "ç¦å†ˆ": "fk", "åšå¤š": "bd", "å¤©ç¥": "ts", "ä¸­æ´²": "zz", "ç¦å†ˆç«™": "fkz",
        "åšå¤šç«™": "bdz", "è¥¿æ–°": "xx", "å¤§æ¿ å…¬å›­": "dhgy", "è¯é™¢": "yy", "èµ¤å‚": "cs",
        "å…­æœ¬æ¾": "lbs", "è¥¿å…¬å›­": "xgy", "ä¸œå…¬å›­": "dgy", "ç™¾é“": "bd", "æ—©è‰¯": "zl",
        
        # æœ­å¹Œå¸‚
        "æœ­å¹Œ": "zl", "å¤§é€š": "dt", "è–„é‡": "bn", "æœ­å¹Œç«™": "zlz", "æ–°æœ­å¹Œ": "xzl",
        "ç™½çŸ³": "bs", "åšåˆ«": "hb", "æ¸…ç”°": "qt", "ä¸°å¹³": "fp", "å—åŒº": "nq",
        "è¥¿åŒº": "xq", "åŒ—åŒº": "bq", "ä¸œåŒº": "dq", "ä¸­å¤®åŒº": "zyq", "æ‰‹ç¨»": "sd",
        
        # ä»™å°å¸‚
        "ä»™å°": "xt", "ä»™å°ç«™": "xtz", "é’å¶é€š": "qyt", "ä¸€ç•ªç”º": "yfm", "äºŒç•ªç”º": "efm",
        "ä¸‰ç•ªç”º": "sfm", "å››ç•ªç”º": "sfm", "äº”ç•ªç”º": "wfm", "å…­ç•ªç”º": "lfm", "ä¸ƒç•ªç”º": "qfm",
        "å…«ç•ªç”º": "bfm", "ä¹ç•ªç”º": "jfm", "åç•ªç”º": "sfm", "å®šç¦…å¯ºé€š": "dzst", "å¹¿æ¿‘é€š": "hst",
        
        # å¹¿å²›å¸‚
        "å¹¿å²›": "hd", "å¹¿å²›ç«™": "hdz", "å…«ä¸å €": "bcdk", "æœ¬é€š": "bt", "çº¸å±‹ç”º": "zym",
        "èƒ¡ç”º": "hm", "å¹Ÿç”º": "zm", "ä¸­ç”º": "zm", "è¢‹ç”º": "dm", "å°ç”º": "xm",
        "åŸºç”º": "jm", "æ±Ÿæ³¢": "jb", "èˆŸå…¥": "fr", "åƒç”°": "qd", "ä½ä¼¯åŒº": "zbq",
        
        # å…¶ä»–ä¸»è¦åŸå¸‚
        "å¥ˆè‰¯": "nl", "å¥ˆè‰¯ç«™": "nlz", "ä¸œå¤§å¯º": "dds", "æ˜¥æ—¥å¤§ç¤¾": "csds", "å…´ç¦å¯º": "xfs",
        "é•¿é‡": "cn", "é•¿é‡ç«™": "cnz", "å–„å…‰å¯º": "sgs", "æ¾æœ¬": "sb", "æ¾æœ¬ç«™": "sbz",
        "é‡‘æ³½": "jz", "é‡‘æ³½ç«™": "jzz", "å…¼å…­å›­": "jly", "ä¸œèŒ¶å±‹è¡—": "dcjj", "è¥¿èŒ¶å±‹è¡—": "xcjj",
        "å†²ç»³": "cs", "é‚£éœ¸": "nb", "é‚£éœ¸ç«™": "nbz", "å›½é™…é€š": "gjt", "é¦–é‡Œ": "sl",
        "å‡½é¦†": "hg", "å‡½é¦†ç«™": "hgz", "äº”æ£±éƒ­": "wlk", "å…ƒç”º": "ym", "æ±¤ä¹‹å·": "yzk"
    }
    
    def normalize(self, input_text: str, remove_stop_words: bool = True) -> Set[str]:
        """å½’ä¸€åŒ–æŸ¥è¯¢è¯"""
        if not input_text:
            return set()
        
        # åŸºæœ¬æ¸…ç†
        cleaned = self._clean_input(input_text)
        
        # ç§»é™¤åœç”¨è¯
        if remove_stop_words:
            cleaned = self._remove_stop_words(cleaned)
        
        result = {cleaned} if cleaned else set()
        
        # æ·»åŠ æ‹¼éŸ³å˜ä½“
        result.update(self._generate_pinyin_variants(cleaned))
        
        # æ·»åŠ è‹±æ–‡å˜ä½“
        result.update(self._generate_english_variants(cleaned))
        
        # æ·»åŠ æ—¥æ–‡å˜ä½“
        result.update(self._generate_japanese_variants(cleaned))
        
        return result
    
    def _clean_input(self, input_text: str) -> str:
        """æ¸…ç†è¾“å…¥"""
        return input_text.lower().strip()
    
    def _remove_stop_words(self, input_text: str) -> str:
        """ç§»é™¤åœç”¨è¯"""
        result = input_text
        for stop_word in self.STOP_WORDS:
            result = result.replace(stop_word.lower(), '')
        return result.strip()
    
    def _generate_pinyin_variants(self, input_text: str) -> Set[str]:
        """ç”Ÿæˆæ‹¼éŸ³å˜ä½“"""
        variants = set()
        if self._contains_chinese(input_text):
            pinyin = self.JAPAN_PINYIN_MAP.get(input_text, '')
            if pinyin:
                variants.add(pinyin)
        return variants
    
    def _generate_english_variants(self, input_text: str) -> Set[str]:
        """ç”Ÿæˆè‹±æ–‡å˜ä½“"""
        variants = set()
        if self._contains_english(input_text):
            variants.add(input_text.lower())
            if input_text:
                variants.add(input_text[0].upper() + input_text[1:].lower())
        return variants
    
    def _generate_japanese_variants(self, input_text: str) -> Set[str]:
        """ç”Ÿæˆæ—¥æ–‡å˜ä½“"""
        variants = set()
        if self._contains_japanese(input_text):
            # è¿™é‡Œå¯ä»¥æ·»åŠ æ—¥æ–‡å‡åè½¬æ¢é€»è¾‘
            variants.add(input_text)
        return variants
    
    def _contains_chinese(self, text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦"""
        return any('\u4e00' <= char <= '\u9fff' for char in text)
    
    def _contains_english(self, text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«è‹±æ–‡å­—ç¬¦"""
        return any(char.isalpha() and ord(char) < 128 for char in text)
    
    def _contains_japanese(self, text: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«æ—¥æ–‡å­—ç¬¦"""
        return any('\u3040' <= char <= '\u309f' or '\u30a0' <= char <= '\u30ff' for char in text)

class JapanHotelSearchSystem:
    """æ—¥æœ¬é…’åº—æœç´¢ç³»ç»Ÿ"""
    
    def __init__(self, data_file: str = "data/japan_hotels.json"):
        self.normalizer = JapanHotelQueryNormalizer()
        self.hotels = self._load_hotel_data(data_file)
        self.suggest_index = self._build_suggest_index()
    
    def _load_hotel_data(self, data_file: str) -> List[JapanHotelInfo]:
        """ä»JSONæ–‡ä»¶åŠ è½½é…’åº—æ•°æ®"""
        try:
            # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
            current_dir = os.path.dirname(os.path.abspath(__file__))
            data_path = os.path.join(current_dir, data_file)
            
            with open(data_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            hotels = []
            for hotel_data in data['hotels']:
                hotel = JapanHotelInfo(
                    hotel_id=hotel_data['hotel_id'],
                    hotel_name_cn=hotel_data['hotel_name_cn'],
                    hotel_name_en=hotel_data['hotel_name_en'],
                    hotel_name_jp=hotel_data['hotel_name_jp'],
                    city_name_cn=hotel_data['city_name_cn'],
                    city_name_en=hotel_data['city_name_en'],
                    city_name_jp=hotel_data['city_name_jp'],
                    region_name=hotel_data['region_name'],
                    address=hotel_data['address'],
                    country=hotel_data['country'],
                    search_count=hotel_data['search_count'],
                    latitude=hotel_data.get('latitude'),
                    longitude=hotel_data.get('longitude'),
                    price_range=hotel_data.get('price_range', ''),
                    star_rating=hotel_data.get('star_rating', 0)
                )
                hotels.append(hotel)
            
            print(f"âœ… æˆåŠŸåŠ è½½ {len(hotels)} å®¶é…’åº—æ•°æ®")
            return hotels
            
        except FileNotFoundError:
            print(f"âŒ æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°: {data_file}")
            return []
        except json.JSONDecodeError as e:
            print(f"âŒ JSONæ–‡ä»¶è§£æé”™è¯¯: {e}")
            return []
        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return []
    
    def _build_suggest_index(self) -> Dict[str, List[JapanHotelInfo]]:
        """æ„å»ºå»ºè®®ç´¢å¼•"""
        index = defaultdict(list)
        
        for hotel in self.hotels:
            # æ·»åŠ é…’åº—åç§°
            for normalized in self.normalizer.normalize(hotel.hotel_name_cn):
                index[normalized].append(hotel)
            for normalized in self.normalizer.normalize(hotel.hotel_name_en):
                index[normalized].append(hotel)
            for normalized in self.normalizer.normalize(hotel.hotel_name_jp):
                index[normalized].append(hotel)
            
            # æ·»åŠ åŸå¸‚åç§°
            for normalized in self.normalizer.normalize(hotel.city_name_cn):
                index[normalized].append(hotel)
            for normalized in self.normalizer.normalize(hotel.city_name_en):
                index[normalized].append(hotel)
            for normalized in self.normalizer.normalize(hotel.city_name_jp):
                index[normalized].append(hotel)
            
            # æ·»åŠ åŒºåŸŸåç§°
            for normalized in self.normalizer.normalize(hotel.region_name):
                index[normalized].append(hotel)
        
        return dict(index)
    
    def suggest(self, query: str, count: int = 10) -> List[JapanHotelSuggestElem]:
        """æ—¥æœ¬é…’åº—å»ºè®®æœç´¢"""
        if not query or len(query.strip()) <= 1:
            return []
        
        query = query.strip()
        candidates = []
        
        # æŸ¥æ‰¾åŒ¹é…çš„é…’åº—
        for normalized_query in self.normalizer.normalize(query, False):
            for prefix in self.suggest_index.keys():
                if prefix.startswith(normalized_query) or normalized_query.startswith(prefix):
                    candidates.extend(self.suggest_index[prefix])
        
        # å»é‡å’Œè¯„åˆ†
        hotel_scores = defaultdict(float)
        for hotel in candidates:
            score = self._compute_suggest_score(hotel, query)
            hotel_scores[hotel.hotel_id] = max(hotel_scores[hotel.hotel_id], score)
        
        # æ’åºå’Œè¿”å›
        sorted_hotels = sorted(hotel_scores.items(), key=lambda x: x[1], reverse=True)
        
        result = []
        seen_hotels = set()
        
        for hotel_id, score in sorted_hotels:
            if len(result) >= count:
                break
            
            hotel = next(h for h in self.hotels if h.hotel_id == hotel_id)
            if hotel.hotel_id not in seen_hotels:
                seen_hotels.add(hotel.hotel_id)
                result.append(JapanHotelSuggestElem(
                    display_name=f"{hotel.hotel_name_cn} ({hotel.city_name_cn})",
                    hotel_name=hotel.hotel_name_cn,
                    city_name=hotel.city_name_cn,
                    region_name=hotel.region_name,
                    country=hotel.country,
                    hotel_id=hotel.hotel_id,
                    price_range=hotel.price_range,
                    star_rating=hotel.star_rating
                ))
        
        return result
    
    def _compute_suggest_score(self, hotel: JapanHotelInfo, query: str) -> float:
        """è®¡ç®—å»ºè®®è¯„åˆ†"""
        search_count_score = (hotel.search_count + 1) ** 0.2
        
        # è®¡ç®—ç¼–è¾‘è·ç¦»åˆ†æ•°
        distance_scores = []
        for field in [hotel.hotel_name_cn, hotel.hotel_name_en, hotel.hotel_name_jp, 
                     hotel.city_name_cn, hotel.city_name_en, hotel.city_name_jp, hotel.region_name]:
            distance_scores.append(self._edit_distance(field, query))
        
        distance_score = max(distance_scores) if distance_scores else 0
        
        # é•¿åº¦å› å­
        length_factor = 2.0 / len(hotel.hotel_name_cn)
        
        # åŒ…å«å› å­
        contain_boost = 10.0 if query in hotel.hotel_name_cn or query in hotel.city_name_cn else 1.0
        
        return (search_count_score * 0.2 + distance_score * 0.6 + length_factor) * contain_boost
    
    def _edit_distance(self, str1: str, str2: str) -> float:
        """è®¡ç®—ç¼–è¾‘è·ç¦»ç›¸ä¼¼åº¦"""
        len1, len2 = len(str1), len(str2)
        matrix = [[0] * (len2 + 1) for _ in range(len1 + 1)]
        
        for i in range(len1 + 1):
            matrix[i][0] = i
        for j in range(len2 + 1):
            matrix[0][j] = j
        
        for i in range(1, len1 + 1):
            for j in range(1, len2 + 1):
                cost = 0 if str1[i-1] == str2[j-1] else 1
                matrix[i][j] = min(
                    matrix[i-1][j] + 1,
                    matrix[i][j-1] + 1,
                    matrix[i-1][j-1] + cost
                )
        
        distance = matrix[len1][len2]
        max_len = max(len1, len2)
        return 1.0 - (distance / max_len) if max_len > 0 else 1.0

def test_japan_hotels():
    """æµ‹è¯•æ—¥æœ¬é…’åº—æœç´¢åŠŸèƒ½"""
    print("ğŸ—¾ æ—¥æœ¬é…’åº—æœç´¢ç³»ç»Ÿæµ‹è¯•")
    print("=" * 60)
    
    # åˆå§‹åŒ–æœç´¢ç³»ç»Ÿ
    system = JapanHotelSearchSystem()
    
    if not system.hotels:
        print("âŒ æ— æ³•åŠ è½½é…’åº—æ•°æ®ï¼Œæµ‹è¯•ç»ˆæ­¢")
        return
    
    # æµ‹è¯•æ—¥æœ¬ä¸»è¦åŸå¸‚
    print("\nğŸ™ï¸ æµ‹è¯•æ—¥æœ¬ä¸»è¦åŸå¸‚æœç´¢:")
    japan_cities = [
        "ä¸œäº¬", "å¤§é˜ª", "äº¬éƒ½", "æ¨ªæ»¨", "åå¤å±‹", "ç¥æˆ·", "ç¦å†ˆ", "æœ­å¹Œ", "ä»™å°", "å¹¿å²›",
        "å¥ˆè‰¯", "é•¿é‡", "é‡‘æ³½", "å†²ç»³", "å‡½é¦†"
    ]
    
    for city in japan_cities:
        print(f"\nğŸ“ æœç´¢åŸå¸‚: '{city}'")
        suggestions = system.suggest(city, 3)
        for i, suggestion in enumerate(suggestions, 1):
            print(f"  {i}. {suggestion.display_name}")
            print(f"     åŒºåŸŸ: {suggestion.region_name} | ä»·æ ¼: {suggestion.price_range} | æ˜Ÿçº§: {suggestion.star_rating}æ˜Ÿ")
    
    # æµ‹è¯•ä¸œäº¬åœ°åŒº
    print("\n\nğŸ¢ æµ‹è¯•ä¸œäº¬åœ°åŒºé…’åº—:")
    tokyo_areas = ["æ–°å®¿", "æ¶©è°·", "æ± è¢‹", "ç§‹å¶åŸ", "æµ…è‰", "ä¸Šé‡", "é“¶åº§", "ç­‘åœ°", "å“å·", "æ—¥æœ¬æ¡¥"]
    
    for area in tokyo_areas:
        print(f"\nğŸ¨ æœç´¢åŒºåŸŸ: '{area}'")
        suggestions = system.suggest(area, 2)
        for i, suggestion in enumerate(suggestions, 1):
            print(f"  {i}. {suggestion.display_name}")
            print(f"     ä»·æ ¼: {suggestion.price_range} | æ˜Ÿçº§: {suggestion.star_rating}æ˜Ÿ")
    
    # æµ‹è¯•è‹±æ–‡æœç´¢
    print("\n\nğŸŒ æµ‹è¯•è‹±æ–‡æœç´¢:")
    english_queries = ["Tokyo", "Osaka", "Kyoto", "Yokohama", "Nagoya", "Kobe", "Fukuoka", "Sapporo"]
    
    for query in english_queries:
        print(f"\nğŸ” è‹±æ–‡æœç´¢: '{query}'")
        suggestions = system.suggest(query, 2)
        for i, suggestion in enumerate(suggestions, 1):
            print(f"  {i}. {suggestion.display_name}")
    
    # æµ‹è¯•é…’åº—å“ç‰Œ
    print("\n\nğŸ¨ æµ‹è¯•é…’åº—å“ç‰Œæœç´¢:")
    hotel_brands = ["å¨æ–¯æ±€", "Westin", "ç‹å­", "Prince", "ä¸‰äº•èŠ±å›­", "Mitsui Garden", "MYSTAYS"]
    
    for brand in hotel_brands:
        print(f"\nğŸ¢ æœç´¢å“ç‰Œ: '{brand}'")
        suggestions = system.suggest(brand, 3)
        for i, suggestion in enumerate(suggestions, 1):
            print(f"  {i}. {suggestion.display_name}")
            print(f"     ä»·æ ¼: {suggestion.price_range} | æ˜Ÿçº§: {suggestion.star_rating}æ˜Ÿ")
    
    # æµ‹è¯•ä»·æ ¼èŒƒå›´
    print("\n\nğŸ’° æµ‹è¯•ä»·æ ¼èŒƒå›´æœç´¢:")
    price_queries = ["ä¾¿å®œ", "ç»æµ", "è±ªå", "é«˜çº§", "å•†åŠ¡"]
    
    for query in price_queries:
        print(f"\nğŸ’µ æœç´¢ä»·æ ¼: '{query}'")
        suggestions = system.suggest(query, 3)
        for i, suggestion in enumerate(suggestions, 1):
            print(f"  {i}. {suggestion.display_name}")
            print(f"     ä»·æ ¼: {suggestion.price_range} | æ˜Ÿçº§: {suggestion.star_rating}æ˜Ÿ")
    
    # æµ‹è¯•å½’ä¸€åŒ–åŠŸèƒ½
    print("\n\nğŸ”„ æµ‹è¯•æŸ¥è¯¢å½’ä¸€åŒ–:")
    normalize_tests = [
        "ä¸œäº¬é…’åº—", "Tokyo Hotel", "å¤§é˜ªãƒ›ãƒ†ãƒ«", "äº¬éƒ½æ—…é¦†", "æ¨ªæ»¨å®¾é¦†",
        "æ–°å®¿åœ°åŒº", "æ¢…ç”°ç«™å‰", "å¿ƒæ–‹æ¡¥é™„è¿‘", "ç¥—å›­å‘¨è¾¹", "åšå¤šç«™"
    ]
    
    for query in normalize_tests:
        normalized = system.normalizer.normalize(query)
        print(f"'{query}' -> {normalized}")

def test_performance():
    """æ€§èƒ½æµ‹è¯•"""
    print("\n\nâš¡ æ€§èƒ½æµ‹è¯•:")
    print("=" * 60)
    
    system = JapanHotelSearchSystem()
    
    if not system.hotels:
        print("âŒ æ— æ³•åŠ è½½é…’åº—æ•°æ®ï¼Œæ€§èƒ½æµ‹è¯•ç»ˆæ­¢")
        return
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = ["ä¸œäº¬", "å¤§é˜ª", "äº¬éƒ½", "æ–°å®¿", "ç§‹å¶åŸ", "tokyo", "osaka", "kyoto"] * 10
    
    start_time = time.time()
    success_count = 0
    
    for query in test_queries:
        try:
            suggestions = system.suggest(query, 5)
            if suggestions:
                success_count += 1
        except Exception as e:
            print(f"æŸ¥è¯¢ '{query}' æ—¶å‘ç”Ÿé”™è¯¯: {e}")
    
    end_time = time.time()
    total_time = end_time - start_time
    avg_time = total_time / len(test_queries) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
    
    print(f"æ€»æŸ¥è¯¢æ•°: {len(test_queries)}")
    print(f"æˆåŠŸæŸ¥è¯¢æ•°: {success_count}")
    print(f"æˆåŠŸç‡: {success_count/len(test_queries)*100:.2f}%")
    print(f"æ€»è€—æ—¶: {total_time:.3f}ç§’")
    print(f"å¹³å‡è€—æ—¶: {avg_time:.2f}æ¯«ç§’")
    print(f"QPS: {len(test_queries)/total_time:.2f}")

if __name__ == "__main__":
    # è¿è¡ŒåŠŸèƒ½æµ‹è¯•
    test_japan_hotels()
    
    # è¿è¡Œæ€§èƒ½æµ‹è¯•
    test_performance() 